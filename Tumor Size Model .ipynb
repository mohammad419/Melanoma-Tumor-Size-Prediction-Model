{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Regression Project: Melanoma Tumor Size Prediction\n",
    "\n",
    "\n",
    "## Loading Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, StackingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.util import Colours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load: Melanoma Tumor Size into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'E:/Data_Sets/Train_15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass_npea</th>\n",
       "      <th>size_npear</th>\n",
       "      <th>malign_ratio</th>\n",
       "      <th>damage_size</th>\n",
       "      <th>exposed_area</th>\n",
       "      <th>std_dev_malign</th>\n",
       "      <th>err_malign</th>\n",
       "      <th>malign_penalty</th>\n",
       "      <th>damage_ratio</th>\n",
       "      <th>tumor_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6930.90</td>\n",
       "      <td>2919.02</td>\n",
       "      <td>0.42116</td>\n",
       "      <td>51.8298</td>\n",
       "      <td>9.888294e+05</td>\n",
       "      <td>109.487</td>\n",
       "      <td>2758.76</td>\n",
       "      <td>72</td>\n",
       "      <td>39.3620</td>\n",
       "      <td>14.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15635.70</td>\n",
       "      <td>4879.36</td>\n",
       "      <td>0.31206</td>\n",
       "      <td>223.5500</td>\n",
       "      <td>2.058426e+06</td>\n",
       "      <td>248.881</td>\n",
       "      <td>5952.53</td>\n",
       "      <td>240</td>\n",
       "      <td>22.0253</td>\n",
       "      <td>2.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10376.20</td>\n",
       "      <td>2613.88</td>\n",
       "      <td>0.25191</td>\n",
       "      <td>127.3370</td>\n",
       "      <td>1.434676e+06</td>\n",
       "      <td>160.093</td>\n",
       "      <td>4635.26</td>\n",
       "      <td>73</td>\n",
       "      <td>29.9963</td>\n",
       "      <td>1.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13093.80</td>\n",
       "      <td>4510.06</td>\n",
       "      <td>0.34444</td>\n",
       "      <td>155.4400</td>\n",
       "      <td>1.812195e+06</td>\n",
       "      <td>173.015</td>\n",
       "      <td>5273.87</td>\n",
       "      <td>32</td>\n",
       "      <td>28.1354</td>\n",
       "      <td>3.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7545.21</td>\n",
       "      <td>2882.36</td>\n",
       "      <td>0.38201</td>\n",
       "      <td>85.1237</td>\n",
       "      <td>1.043918e+06</td>\n",
       "      <td>124.414</td>\n",
       "      <td>3263.35</td>\n",
       "      <td>57</td>\n",
       "      <td>35.0200</td>\n",
       "      <td>18.023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mass_npea  size_npear  malign_ratio  damage_size  exposed_area  \\\n",
       "0    6930.90     2919.02       0.42116      51.8298  9.888294e+05   \n",
       "1   15635.70     4879.36       0.31206     223.5500  2.058426e+06   \n",
       "2   10376.20     2613.88       0.25191     127.3370  1.434676e+06   \n",
       "3   13093.80     4510.06       0.34444     155.4400  1.812195e+06   \n",
       "4    7545.21     2882.36       0.38201      85.1237  1.043918e+06   \n",
       "\n",
       "   std_dev_malign  err_malign  malign_penalty  damage_ratio  tumor_size  \n",
       "0         109.487     2758.76              72       39.3620      14.103  \n",
       "1         248.881     5952.53             240       22.0253       2.648  \n",
       "2         160.093     4635.26              73       29.9963       1.688  \n",
       "3         173.015     5273.87              32       28.1354       3.796  \n",
       "4         124.414     3263.35              57       35.0200      18.023  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass_npea</th>\n",
       "      <th>size_npear</th>\n",
       "      <th>malign_ratio</th>\n",
       "      <th>damage_size</th>\n",
       "      <th>exposed_area</th>\n",
       "      <th>std_dev_malign</th>\n",
       "      <th>err_malign</th>\n",
       "      <th>malign_penalty</th>\n",
       "      <th>damage_ratio</th>\n",
       "      <th>tumor_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9.146000e+03</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9903.052174</td>\n",
       "      <td>3032.827837</td>\n",
       "      <td>0.303083</td>\n",
       "      <td>103.902118</td>\n",
       "      <td>1.372442e+06</td>\n",
       "      <td>146.304239</td>\n",
       "      <td>3992.936256</td>\n",
       "      <td>69.849661</td>\n",
       "      <td>34.461652</td>\n",
       "      <td>7.723348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4060.577116</td>\n",
       "      <td>1462.334147</td>\n",
       "      <td>0.062533</td>\n",
       "      <td>55.456862</td>\n",
       "      <td>5.646773e+05</td>\n",
       "      <td>70.512177</td>\n",
       "      <td>1780.672859</td>\n",
       "      <td>55.785332</td>\n",
       "      <td>5.972808</td>\n",
       "      <td>6.086852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2864.760000</td>\n",
       "      <td>510.530000</td>\n",
       "      <td>0.114820</td>\n",
       "      <td>10.310100</td>\n",
       "      <td>3.878534e+05</td>\n",
       "      <td>31.970400</td>\n",
       "      <td>1089.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.228000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6988.420000</td>\n",
       "      <td>1983.657500</td>\n",
       "      <td>0.259053</td>\n",
       "      <td>64.012525</td>\n",
       "      <td>9.596873e+05</td>\n",
       "      <td>95.853900</td>\n",
       "      <td>3177.682500</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.290225</td>\n",
       "      <td>2.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8895.965000</td>\n",
       "      <td>2684.330000</td>\n",
       "      <td>0.301055</td>\n",
       "      <td>88.458300</td>\n",
       "      <td>1.237057e+06</td>\n",
       "      <td>126.138500</td>\n",
       "      <td>3846.320000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>35.245750</td>\n",
       "      <td>5.060500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12119.950000</td>\n",
       "      <td>3830.745000</td>\n",
       "      <td>0.343002</td>\n",
       "      <td>134.209000</td>\n",
       "      <td>1.693083e+06</td>\n",
       "      <td>182.251500</td>\n",
       "      <td>4664.577500</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>38.806075</td>\n",
       "      <td>13.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36995.400000</td>\n",
       "      <td>13535.000000</td>\n",
       "      <td>0.525300</td>\n",
       "      <td>346.420000</td>\n",
       "      <td>4.978616e+06</td>\n",
       "      <td>528.890000</td>\n",
       "      <td>91983.700000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>46.546400</td>\n",
       "      <td>20.999000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mass_npea    size_npear  malign_ratio  damage_size  exposed_area  \\\n",
       "count   9146.000000   9146.000000   9146.000000  9146.000000  9.146000e+03   \n",
       "mean    9903.052174   3032.827837      0.303083   103.902118  1.372442e+06   \n",
       "std     4060.577116   1462.334147      0.062533    55.456862  5.646773e+05   \n",
       "min     2864.760000    510.530000      0.114820    10.310100  3.878534e+05   \n",
       "25%     6988.420000   1983.657500      0.259053    64.012525  9.596873e+05   \n",
       "50%     8895.965000   2684.330000      0.301055    88.458300  1.237057e+06   \n",
       "75%    12119.950000   3830.745000      0.343002   134.209000  1.693083e+06   \n",
       "max    36995.400000  13535.000000      0.525300   346.420000  4.978616e+06   \n",
       "\n",
       "       std_dev_malign    err_malign  malign_penalty  damage_ratio   tumor_size  \n",
       "count     9146.000000   9146.000000     9146.000000   9146.000000  9146.000000  \n",
       "mean       146.304239   3992.936256       69.849661     34.461652     7.723348  \n",
       "std         70.512177   1780.672859       55.785332      5.972808     6.086852  \n",
       "min         31.970400   1089.190000        0.000000     15.228000     0.000000  \n",
       "25%         95.853900   3177.682500       31.000000     30.290225     2.320000  \n",
       "50%        126.138500   3846.320000       54.000000     35.245750     5.060500  \n",
       "75%        182.251500   4664.577500       91.000000     38.806075    13.336000  \n",
       "max        528.890000  91983.700000      340.000000     46.546400    20.999000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train.pop('tumor_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass_npea</th>\n",
       "      <th>size_npear</th>\n",
       "      <th>malign_ratio</th>\n",
       "      <th>damage_size</th>\n",
       "      <th>exposed_area</th>\n",
       "      <th>std_dev_malign</th>\n",
       "      <th>err_malign</th>\n",
       "      <th>malign_penalty</th>\n",
       "      <th>damage_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.843889</td>\n",
       "      <td>7.979346</td>\n",
       "      <td>0.42116</td>\n",
       "      <td>51.8298</td>\n",
       "      <td>13.804278</td>\n",
       "      <td>109.487</td>\n",
       "      <td>7.922899</td>\n",
       "      <td>72</td>\n",
       "      <td>39.3620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.657376</td>\n",
       "      <td>8.492974</td>\n",
       "      <td>0.31206</td>\n",
       "      <td>223.5500</td>\n",
       "      <td>14.537453</td>\n",
       "      <td>248.881</td>\n",
       "      <td>8.691740</td>\n",
       "      <td>240</td>\n",
       "      <td>22.0253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.247366</td>\n",
       "      <td>7.868973</td>\n",
       "      <td>0.25191</td>\n",
       "      <td>127.3370</td>\n",
       "      <td>14.176450</td>\n",
       "      <td>160.093</td>\n",
       "      <td>8.441663</td>\n",
       "      <td>73</td>\n",
       "      <td>29.9963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.479970</td>\n",
       "      <td>8.414287</td>\n",
       "      <td>0.34444</td>\n",
       "      <td>155.4400</td>\n",
       "      <td>14.410050</td>\n",
       "      <td>173.015</td>\n",
       "      <td>8.570709</td>\n",
       "      <td>32</td>\n",
       "      <td>28.1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.928801</td>\n",
       "      <td>7.966712</td>\n",
       "      <td>0.38201</td>\n",
       "      <td>85.1237</td>\n",
       "      <td>13.858492</td>\n",
       "      <td>124.414</td>\n",
       "      <td>8.090816</td>\n",
       "      <td>57</td>\n",
       "      <td>35.0200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mass_npea  size_npear  malign_ratio  damage_size  exposed_area  \\\n",
       "0   8.843889    7.979346       0.42116      51.8298     13.804278   \n",
       "1   9.657376    8.492974       0.31206     223.5500     14.537453   \n",
       "2   9.247366    7.868973       0.25191     127.3370     14.176450   \n",
       "3   9.479970    8.414287       0.34444     155.4400     14.410050   \n",
       "4   8.928801    7.966712       0.38201      85.1237     13.858492   \n",
       "\n",
       "   std_dev_malign  err_malign  malign_penalty  damage_ratio  \n",
       "0         109.487    7.922899              72       39.3620  \n",
       "1         248.881    8.691740             240       22.0253  \n",
       "2         160.093    8.441663              73       29.9963  \n",
       "3         173.015    8.570709              32       28.1354  \n",
       "4         124.414    8.090816              57       35.0200  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['mass_npea','size_npear','exposed_area','err_malign']] = np.log1p(train[['mass_npea','size_npear','exposed_area','err_malign']])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "## Deriving new columns from the existing in order to have more information available for the model to learn so that it can perform with better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['penalty-err'] = train['malign_penalty'] - train['err_malign']\n",
    "train['d_size-ratio'] = train['damage_size'] - train['damage_ratio']\n",
    "train['d_ratio-m_ratio'] = train['damage_ratio'] - (train['malign_ratio'])\n",
    "train['penalty/std'] = train['malign_penalty']/train['std_dev_malign']\n",
    "train['mass/area'] = (train['mass_npea'])/(train['exposed_area'])\n",
    "train['area/mass'] = train['exposed_area']/train['mass_npea']\n",
    "train['err/std'] = train['penalty-err']/train['std_dev_malign']\n",
    "train['dsr/ps'] = train['damage_size']/train['penalty-err']\n",
    "train['std/area'] = train['std_dev_malign']/train['exposed_area']\n",
    "train['err/area'] = train['err_malign']/train['exposed_area']\n",
    "train['dr/area'] = (train['damage_ratio']*100)/train['exposed_area']\n",
    "train['std/err'] = (train['std_dev_malign']+1)/(train['err_malign']+1)\n",
    "train['penalty/err'] = (train['malign_penalty']+1)/(train['err_malign']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.values\n",
    "y_train = target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true,y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true,y_pred))\n",
    "rmse = make_scorer(RMSE, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of Extratrees Regressor using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etc_cv(n_estimators, min_samples_split, max_features, data, target):\n",
    "    estimator = ExtraTreesRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            min_samples_split=min_samples_split,\n",
    "            max_features=max_features,\n",
    "            random_state=2,\n",
    "            n_jobs=-1\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, target, scoring=rmse, cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_etc(data, target):\n",
    "    def etc_crossval(n_estimators, min_samples_split, max_features):\n",
    "        return etc_cv(\n",
    "                n_estimators=int(n_estimators),\n",
    "                min_samples_split=int(min_samples_split),\n",
    "                max_features=max(min(max_features, 0.999), 1e-3),\n",
    "                data=data,\n",
    "                target=target,\n",
    "                )\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=etc_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\":(100,550),\n",
    "            \"min_samples_split\":(2,25),\n",
    "            \"max_features\": (0.1,0.9)\n",
    "        },\n",
    "        random_state=42,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=15, init_points=10)\n",
    "    \n",
    "    print(\"Final result:\", optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m--- Optimizing Extra Trees ---\u001b[0m\n",
      "|   iter    |  target   | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-4.108   \u001b[0m | \u001b[0m 0.3996  \u001b[0m | \u001b[0m 23.87   \u001b[0m | \u001b[0m 429.4   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-3.825   \u001b[0m | \u001b[95m 0.5789  \u001b[0m | \u001b[95m 5.588   \u001b[0m | \u001b[95m 170.2   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-4.225   \u001b[0m | \u001b[0m 0.1465  \u001b[0m | \u001b[0m 21.92   \u001b[0m | \u001b[0m 370.5   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-3.787   \u001b[0m | \u001b[95m 0.6665  \u001b[0m | \u001b[95m 2.473   \u001b[0m | \u001b[95m 536.5   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-3.835   \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 6.884   \u001b[0m | \u001b[0m 181.8   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-3.921   \u001b[0m | \u001b[0m 0.2467  \u001b[0m | \u001b[0m 8.998   \u001b[0m | \u001b[0m 336.1   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-3.873   \u001b[0m | \u001b[0m 0.4456  \u001b[0m | \u001b[0m 8.698   \u001b[0m | \u001b[0m 375.3   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-3.948   \u001b[0m | \u001b[0m 0.2116  \u001b[0m | \u001b[0m 8.719   \u001b[0m | \u001b[0m 264.9   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-4.063   \u001b[0m | \u001b[0m 0.4649  \u001b[0m | \u001b[0m 20.06   \u001b[0m | \u001b[0m 189.9   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-3.986   \u001b[0m | \u001b[0m 0.5114  \u001b[0m | \u001b[0m 15.63   \u001b[0m | \u001b[0m 120.9   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-3.84    \u001b[0m | \u001b[0m 0.6767  \u001b[0m | \u001b[0m 7.548   \u001b[0m | \u001b[0m 175.7   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-3.881   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 10.75   \u001b[0m | \u001b[0m 541.0   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-3.803   \u001b[0m | \u001b[0m 0.3417  \u001b[0m | \u001b[0m 3.967   \u001b[0m | \u001b[0m 526.6   \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-3.779   \u001b[0m | \u001b[95m 0.7611  \u001b[0m | \u001b[95m 2.169   \u001b[0m | \u001b[95m 389.2   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-3.784   \u001b[0m | \u001b[0m 0.6213  \u001b[0m | \u001b[0m 2.003   \u001b[0m | \u001b[0m 402.8   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-3.945   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 14.46   \u001b[0m | \u001b[0m 397.7   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-3.787   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 506.9   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-3.993   \u001b[0m | \u001b[0m 0.8874  \u001b[0m | \u001b[0m 18.33   \u001b[0m | \u001b[0m 508.6   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-3.79    \u001b[0m | \u001b[0m 0.3631  \u001b[0m | \u001b[0m 2.361   \u001b[0m | \u001b[0m 493.0   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-3.895   \u001b[0m | \u001b[0m 0.1227  \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 475.7   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-3.797   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 151.7   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-4.286   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 18.08   \u001b[0m | \u001b[0m 154.1   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-3.793   \u001b[0m | \u001b[0m 0.3326  \u001b[0m | \u001b[0m 2.301   \u001b[0m | \u001b[0m 414.4   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-4.244   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 16.14   \u001b[0m | \u001b[0m 486.3   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-3.795   \u001b[0m | \u001b[0m 0.4644  \u001b[0m | \u001b[0m 2.139   \u001b[0m | \u001b[0m 138.1   \u001b[0m |\n",
      "=============================================================\n",
      "Final result: {'target': -3.7786805756406823, 'params': {'max_features': 0.761053890090604, 'min_samples_split': 2.169127366533436, 'n_estimators': 389.1643211846736}}\n"
     ]
    }
   ],
   "source": [
    "print(Colours.yellow(\"--- Optimizing Extra Trees ---\"))\n",
    "optimize_etc(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = ExtraTreesRegressor(n_estimators=int(389.1643211846736),\n",
    "                         min_samples_split=int(2.169127366533436),\n",
    "                         max_features=0.761053890090604,\n",
    "                         n_jobs = -1,\n",
    "                         random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of RandomForest Regressor using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_cv(n_estimators, min_samples_split, max_features, data, target):\n",
    "    estimator = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            min_samples_split=min_samples_split,\n",
    "            max_features=max_features,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, target, scoring=rmse, cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_rfc(data, target):\n",
    "    def rfc_crossval(n_estimators, min_samples_split, max_features):\n",
    "        return rfc_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            max_features=max(min(max_features, 0.9), 1e-3),\n",
    "            data=data,\n",
    "            target=target,\n",
    "            )\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=rfc_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\":(100,600),\n",
    "            \"min_samples_split\":(2,25),\n",
    "            \"max_features\":(0.1,0.9),\n",
    "        },\n",
    "        random_state=1234,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=15, init_points=10)\n",
    "    \n",
    "    print(\"Final result:\", optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m--- Optimizing Random Forest ---\u001b[0m\n",
      "|   iter    |  target   | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-4.054   \u001b[0m | \u001b[0m 0.2532  \u001b[0m | \u001b[0m 16.31   \u001b[0m | \u001b[0m 318.9   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-4.096   \u001b[0m | \u001b[0m 0.7283  \u001b[0m | \u001b[0m 19.94   \u001b[0m | \u001b[0m 236.3   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-4.078   \u001b[0m | \u001b[0m 0.3212  \u001b[0m | \u001b[0m 20.44   \u001b[0m | \u001b[0m 579.1   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-4.018   \u001b[0m | \u001b[95m 0.8007  \u001b[0m | \u001b[95m 10.23   \u001b[0m | \u001b[95m 350.5   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-4.086   \u001b[0m | \u001b[0m 0.6468  \u001b[0m | \u001b[0m 18.39   \u001b[0m | \u001b[0m 285.1   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-4.043   \u001b[0m | \u001b[0m 0.549   \u001b[0m | \u001b[0m 13.57   \u001b[0m | \u001b[0m 106.9   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-4.117   \u001b[0m | \u001b[0m 0.7183  \u001b[0m | \u001b[0m 22.3    \u001b[0m | \u001b[0m 282.4   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-3.945   \u001b[0m | \u001b[95m 0.5923  \u001b[0m | \u001b[95m 3.734   \u001b[0m | \u001b[95m 284.4   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-4.078   \u001b[0m | \u001b[0m 0.8465  \u001b[0m | \u001b[0m 16.98   \u001b[0m | \u001b[0m 298.6   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-4.005   \u001b[0m | \u001b[0m 0.731   \u001b[0m | \u001b[0m 9.287   \u001b[0m | \u001b[0m 384.0   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-3.925   \u001b[0m | \u001b[95m 0.3175  \u001b[0m | \u001b[95m 3.385   \u001b[0m | \u001b[95m 278.8   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-3.97    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 266.7   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-4.127   \u001b[0m | \u001b[0m 0.6755  \u001b[0m | \u001b[0m 24.99   \u001b[0m | \u001b[0m 407.5   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-4.211   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 368.0   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-3.966   \u001b[0m | \u001b[0m 0.7866  \u001b[0m | \u001b[0m 2.612   \u001b[0m | \u001b[0m 334.9   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-3.95    \u001b[0m | \u001b[0m 0.4432  \u001b[0m | \u001b[0m 3.185   \u001b[0m | \u001b[0m 147.5   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-4.031   \u001b[0m | \u001b[0m 0.4385  \u001b[0m | \u001b[0m 14.21   \u001b[0m | \u001b[0m 160.3   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-3.961   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 132.5   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-4.117   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 19.35   \u001b[0m | \u001b[0m 137.0   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-3.974   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 183.8   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-4.065   \u001b[0m | \u001b[0m 0.3799  \u001b[0m | \u001b[0m 17.26   \u001b[0m | \u001b[0m 193.0   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-3.961   \u001b[0m | \u001b[0m 0.7083  \u001b[0m | \u001b[0m 2.049   \u001b[0m | \u001b[0m 170.2   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-3.96    \u001b[0m | \u001b[0m 0.7834  \u001b[0m | \u001b[0m 2.128   \u001b[0m | \u001b[0m 495.7   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-4.088   \u001b[0m | \u001b[0m 0.5929  \u001b[0m | \u001b[0m 20.42   \u001b[0m | \u001b[0m 494.2   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-3.968   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 511.6   \u001b[0m |\n",
      "=============================================================\n",
      "Final result: {'target': -3.9253782373087516, 'params': {'max_features': 0.31748183480254244, 'min_samples_split': 3.3847745086807413, 'n_estimators': 278.823003027616}}\n"
     ]
    }
   ],
   "source": [
    "print(Colours.green(\"--- Optimizing Random Forest ---\"))\n",
    "optimize_rfc(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestRegressor(n_estimators = int(278.823003027616),\n",
    "                           min_samples_split=int(3.3847745086807413),\n",
    "                           max_features = 0.31748183480254244,\n",
    "                           n_jobs = -1, \n",
    "                           random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of LightGradientBoosting Regressor using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_cv(n_estimators, num_leaves, min_child_samples, subsample, data, target):\n",
    "    estimator = LGBMRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        num_leaves=num_leaves,\n",
    "        min_child_samples=min_child_samples,\n",
    "        subsample=subsample,\n",
    "        random_state=2\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, target, scoring=rmse, cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_lgb(data, targets):\n",
    "    def lgb_crossval(n_estimators, num_leaves, min_child_samples, subsample):\n",
    "        return lgb_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "            num_leaves= int(num_leaves),\n",
    "            min_child_samples=int(min_child_samples),\n",
    "            subsample=subsample,\n",
    "            data=data,\n",
    "            target=target,\n",
    "        )\n",
    "    \n",
    "    optimizer = BayesianOptimization(\n",
    "        f=lgb_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\":(100,550),\n",
    "            \"num_leaves\":(30,90),\n",
    "            \"min_child_samples\":(5,30),\n",
    "            \"subsample\":(0.6,1.0)\n",
    "        },\n",
    "        random_state=1234,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=15, init_points=10)\n",
    "    \n",
    "    print(\"Final result:\", optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m--- Optimizing Light GBM ---\u001b[0m\n",
      "|   iter    |  target   | min_ch... | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-3.949   \u001b[0m | \u001b[0m 9.788   \u001b[0m | \u001b[0m 379.9   \u001b[0m | \u001b[0m 56.26   \u001b[0m | \u001b[0m 0.9141  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-3.989   \u001b[0m | \u001b[0m 24.5    \u001b[0m | \u001b[0m 222.7   \u001b[0m | \u001b[0m 46.59   \u001b[0m | \u001b[0m 0.9207  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-3.948   \u001b[0m | \u001b[95m 28.95   \u001b[0m | \u001b[95m 494.2   \u001b[0m | \u001b[95m 51.47   \u001b[0m | \u001b[95m 0.8004  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-3.959   \u001b[0m | \u001b[0m 22.09   \u001b[0m | \u001b[0m 420.7   \u001b[0m | \u001b[0m 52.22   \u001b[0m | \u001b[0m 0.8245  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-3.982   \u001b[0m | \u001b[0m 17.58   \u001b[0m | \u001b[0m 106.2   \u001b[0m | \u001b[0m 76.37   \u001b[0m | \u001b[0m 0.9531  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-3.986   \u001b[0m | \u001b[0m 14.12   \u001b[0m | \u001b[0m 376.9   \u001b[0m | \u001b[0m 34.52   \u001b[0m | \u001b[0m 0.7475  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-3.962   \u001b[0m | \u001b[0m 28.33   \u001b[0m | \u001b[0m 393.1   \u001b[0m | \u001b[0m 53.83   \u001b[0m | \u001b[0m 0.9155  \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-3.929   \u001b[0m | \u001b[95m 12.92   \u001b[0m | \u001b[95m 355.6   \u001b[0m | \u001b[95m 82.15   \u001b[0m | \u001b[95m 0.7745  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-3.961   \u001b[0m | \u001b[0m 25.05   \u001b[0m | \u001b[0m 164.7   \u001b[0m | \u001b[0m 72.26   \u001b[0m | \u001b[0m 0.8818  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-3.931   \u001b[0m | \u001b[0m 10.47   \u001b[0m | \u001b[0m 516.2   \u001b[0m | \u001b[0m 56.53   \u001b[0m | \u001b[0m 0.9637  \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-3.922   \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 378.0   \u001b[0m | \u001b[95m 88.91   \u001b[0m | \u001b[95m 0.9786  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-3.928   \u001b[0m | \u001b[0m 6.382   \u001b[0m | \u001b[0m 379.4   \u001b[0m | \u001b[0m 88.43   \u001b[0m | \u001b[0m 0.976   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-3.943   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 366.1   \u001b[0m | \u001b[0m 89.84   \u001b[0m | \u001b[0m 0.9313  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-3.935   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 373.7   \u001b[0m | \u001b[0m 80.67   \u001b[0m | \u001b[0m 0.8658  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-3.93    \u001b[0m | \u001b[0m 10.94   \u001b[0m | \u001b[0m 357.3   \u001b[0m | \u001b[0m 70.88   \u001b[0m | \u001b[0m 0.9204  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-3.924   \u001b[0m | \u001b[0m 14.64   \u001b[0m | \u001b[0m 343.6   \u001b[0m | \u001b[0m 75.14   \u001b[0m | \u001b[0m 0.8387  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-3.942   \u001b[0m | \u001b[0m 25.28   \u001b[0m | \u001b[0m 351.8   \u001b[0m | \u001b[0m 74.66   \u001b[0m | \u001b[0m 0.8553  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-3.943   \u001b[0m | \u001b[0m 7.223   \u001b[0m | \u001b[0m 340.2   \u001b[0m | \u001b[0m 85.33   \u001b[0m | \u001b[0m 0.9442  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-3.95    \u001b[0m | \u001b[0m 8.555   \u001b[0m | \u001b[0m 344.0   \u001b[0m | \u001b[0m 64.5    \u001b[0m | \u001b[0m 0.7216  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-3.975   \u001b[0m | \u001b[0m 22.67   \u001b[0m | \u001b[0m 334.0   \u001b[0m | \u001b[0m 78.58   \u001b[0m | \u001b[0m 0.8695  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-3.933   \u001b[0m | \u001b[0m 7.048   \u001b[0m | \u001b[0m 349.0   \u001b[0m | \u001b[0m 78.94   \u001b[0m | \u001b[0m 0.9746  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-3.941   \u001b[0m | \u001b[0m 18.83   \u001b[0m | \u001b[0m 365.7   \u001b[0m | \u001b[0m 76.3    \u001b[0m | \u001b[0m 0.6     \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-3.946   \u001b[0m | \u001b[0m 7.573   \u001b[0m | \u001b[0m 524.7   \u001b[0m | \u001b[0m 47.49   \u001b[0m | \u001b[0m 0.7819  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-3.946   \u001b[0m | \u001b[0m 16.17   \u001b[0m | \u001b[0m 513.2   \u001b[0m | \u001b[0m 67.41   \u001b[0m | \u001b[0m 0.688   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-3.957   \u001b[0m | \u001b[0m 6.208   \u001b[0m | \u001b[0m 505.7   \u001b[0m | \u001b[0m 52.36   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "=========================================================================\n",
      "Final result: {'target': -3.9216841543728607, 'params': {'min_child_samples': 5.0, 'n_estimators': 378.03973190498584, 'num_leaves': 88.90759301695284, 'subsample': 0.9786071458754081}}\n"
     ]
    }
   ],
   "source": [
    "print(Colours.blue(\"--- Optimizing Light GBM ---\"))\n",
    "optimize_lgb(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMRegressor(\n",
    "        n_estimators=int(378.03973190498584),\n",
    "        num_leaves = int(88.90759301695284),\n",
    "        min_child_samples=int(5.0),\n",
    "        subsample = 0.9786071458754081,\n",
    "        random_state = 42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of ExtremeGradientBoosting Regressor using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv(n_estimators, max_depth, gamma, min_child_weight, subsample, data, target):\n",
    "    estimator = XGBRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            gamma=gamma,\n",
    "            min_child_weight=min_child_weight,\n",
    "            subsample=subsample,\n",
    "            random_state=2\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, target, scoring=rmse, cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_xgb(data, target):\n",
    "    def xgb_crossval(n_estimators, max_depth, gamma, min_child_weight, subsample):\n",
    "        return xgb_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "            max_depth=int(max_depth),\n",
    "            gamma=gamma,\n",
    "            min_child_weight=min_child_weight,\n",
    "            subsample=subsample,\n",
    "            data=data,\n",
    "            target=target,\n",
    "        )\n",
    "    optimizer = BayesianOptimization(\n",
    "            f=xgb_crossval,\n",
    "            pbounds={\n",
    "                \"n_estimators\":(150,550),\n",
    "                \"max_depth\": (1,20),\n",
    "                \"gamma\":(0,10),\n",
    "                \"min_child_weight\":(0,10),\n",
    "                \"subsample\":(0.8,1.0)\n",
    "                },\n",
    "            random_state=1234,\n",
    "            verbose=2\n",
    "      )\n",
    "    optimizer.maximize(n_iter=15 , init_points=10)\n",
    "    \n",
    "    \n",
    "    print('Final Result:', optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m--- Optimizing XGBoost ---\u001b[0m\n",
      "|   iter    |  target   |   gamma   | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-4.182   \u001b[0m | \u001b[0m 1.915   \u001b[0m | \u001b[0m 12.82   \u001b[0m | \u001b[0m 4.377   \u001b[0m | \u001b[0m 464.1   \u001b[0m | \u001b[0m 0.956   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-4.203   \u001b[0m | \u001b[0m 2.726   \u001b[0m | \u001b[0m 6.253   \u001b[0m | \u001b[0m 8.019   \u001b[0m | \u001b[0m 533.3   \u001b[0m | \u001b[0m 0.9752  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-4.232   \u001b[0m | \u001b[0m 3.578   \u001b[0m | \u001b[0m 10.52   \u001b[0m | \u001b[0m 6.835   \u001b[0m | \u001b[0m 435.1   \u001b[0m | \u001b[0m 0.8741  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-4.221   \u001b[0m | \u001b[0m 5.612   \u001b[0m | \u001b[0m 10.56   \u001b[0m | \u001b[0m 0.1377  \u001b[0m | \u001b[0m 459.1   \u001b[0m | \u001b[0m 0.9765  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-4.187   \u001b[0m | \u001b[0m 3.649   \u001b[0m | \u001b[0m 12.69   \u001b[0m | \u001b[0m 0.7538  \u001b[0m | \u001b[0m 297.5   \u001b[0m | \u001b[0m 0.9866  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-4.182   \u001b[0m | \u001b[0m 6.514   \u001b[0m | \u001b[0m 8.547   \u001b[0m | \u001b[0m 7.887   \u001b[0m | \u001b[0m 276.7   \u001b[0m | \u001b[0m 0.9136  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-4.211   \u001b[0m | \u001b[0m 8.691   \u001b[0m | \u001b[0m 9.287   \u001b[0m | \u001b[0m 8.021   \u001b[0m | \u001b[0m 207.5   \u001b[0m | \u001b[0m 0.9409  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-4.197   \u001b[0m | \u001b[0m 7.046   \u001b[0m | \u001b[0m 5.157   \u001b[0m | \u001b[0m 9.249   \u001b[0m | \u001b[0m 326.9   \u001b[0m | \u001b[0m 0.9819  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-4.179   \u001b[0m | \u001b[95m 0.5981  \u001b[0m | \u001b[95m 4.501   \u001b[0m | \u001b[95m 0.4736  \u001b[0m | \u001b[95m 420.0   \u001b[0m | \u001b[95m 0.9189  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-4.192   \u001b[0m | \u001b[0m 5.333   \u001b[0m | \u001b[0m 1.823   \u001b[0m | \u001b[0m 5.614   \u001b[0m | \u001b[0m 281.9   \u001b[0m | \u001b[0m 0.9006  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-4.207   \u001b[0m | \u001b[0m 5.153   \u001b[0m | \u001b[0m 4.448   \u001b[0m | \u001b[0m 3.77    \u001b[0m | \u001b[0m 180.4   \u001b[0m | \u001b[0m 0.8525  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-4.204   \u001b[0m | \u001b[0m 3.824   \u001b[0m | \u001b[0m 16.61   \u001b[0m | \u001b[0m 4.05    \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 0.9551  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-4.217   \u001b[0m | \u001b[0m 1.111   \u001b[0m | \u001b[0m 5.153   \u001b[0m | \u001b[0m 6.716   \u001b[0m | \u001b[0m 493.7   \u001b[0m | \u001b[0m 0.9595  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-4.21    \u001b[0m | \u001b[0m 8.317   \u001b[0m | \u001b[0m 16.32   \u001b[0m | \u001b[0m 0.9797  \u001b[0m | \u001b[0m 302.3   \u001b[0m | \u001b[0m 0.9759  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-4.222   \u001b[0m | \u001b[0m 8.472   \u001b[0m | \u001b[0m 6.517   \u001b[0m | \u001b[0m 6.877   \u001b[0m | \u001b[0m 169.6   \u001b[0m | \u001b[0m 0.8415  \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m-4.166   \u001b[0m | \u001b[95m 8.48    \u001b[0m | \u001b[95m 1.792   \u001b[0m | \u001b[95m 0.8149  \u001b[0m | \u001b[95m 351.2   \u001b[0m | \u001b[95m 0.9536  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-4.252   \u001b[0m | \u001b[0m 5.608   \u001b[0m | \u001b[0m 7.428   \u001b[0m | \u001b[0m 5.166   \u001b[0m | \u001b[0m 525.3   \u001b[0m | \u001b[0m 0.8213  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-4.201   \u001b[0m | \u001b[0m 3.653   \u001b[0m | \u001b[0m 13.11   \u001b[0m | \u001b[0m 5.402   \u001b[0m | \u001b[0m 548.8   \u001b[0m | \u001b[0m 0.8603  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-4.176   \u001b[0m | \u001b[0m 7.564   \u001b[0m | \u001b[0m 15.97   \u001b[0m | \u001b[0m 3.059   \u001b[0m | \u001b[0m 265.2   \u001b[0m | \u001b[0m 0.9221  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-4.265   \u001b[0m | \u001b[0m 6.385   \u001b[0m | \u001b[0m 15.03   \u001b[0m | \u001b[0m 4.344   \u001b[0m | \u001b[0m 198.9   \u001b[0m | \u001b[0m 0.8045  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-4.205   \u001b[0m | \u001b[0m 4.361   \u001b[0m | \u001b[0m 17.83   \u001b[0m | \u001b[0m 6.2     \u001b[0m | \u001b[0m 454.8   \u001b[0m | \u001b[0m 0.9801  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-4.203   \u001b[0m | \u001b[0m 8.041   \u001b[0m | \u001b[0m 7.955   \u001b[0m | \u001b[0m 6.426   \u001b[0m | \u001b[0m 329.2   \u001b[0m | \u001b[0m 0.8517  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-4.178   \u001b[0m | \u001b[0m 9.069   \u001b[0m | \u001b[0m 1.002   \u001b[0m | \u001b[0m 0.00178 \u001b[0m | \u001b[0m 356.4   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-4.182   \u001b[0m | \u001b[0m 5.526   \u001b[0m | \u001b[0m 2.225   \u001b[0m | \u001b[0m 6.616   \u001b[0m | \u001b[0m 351.9   \u001b[0m | \u001b[0m 0.9656  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-4.246   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 8.638   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 351.3   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "=====================================================================================\n",
      "Final Result: {'target': -4.166001334430921, 'params': {'gamma': 8.47951455118692, 'max_depth': 1.7917534355988143, 'min_child_weight': 0.8148610722659055, 'n_estimators': 351.213709366579, 'subsample': 0.9535874700807384}}\n"
     ]
    }
   ],
   "source": [
    "print(Colours.red(\"--- Optimizing XGBoost ---\"))\n",
    "optimize_xgb(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(\n",
    "        n_estimators=int(351.213709366579),\n",
    "        max_depth = int(1.7917534355988143),\n",
    "        gamma = 8.47951455118692,\n",
    "        min_child_weight = 0.8148610722659055,\n",
    "        subsample = 0.9535874700807384,\n",
    "        random_state = 42,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of ExtremeGradientBoosting and RandomForest Regressor using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv(n_estimators, max_depth, gamma, min_child_weight, subsample, data, targets):\n",
    "    estimator = XGBRFRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth = max_depth,\n",
    "        gamma = gamma,\n",
    "        min_child_weight=min_child_weight,\n",
    "        subsample = subsample,\n",
    "        random_state = 2,\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, targets,\n",
    "                           scoring=rmse, cv=5)\n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_xgb(data, targets):\n",
    "    def xgb_crossval(n_estimators, max_depth, gamma, min_child_weight, subsample):\n",
    "        return xgb_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "            max_depth = int(max_depth),\n",
    "            gamma = gamma,\n",
    "            min_child_weight=min_child_weight,\n",
    "            subsample=subsample,\n",
    "            data=data,\n",
    "            targets=targets,\n",
    "        )\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=xgb_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\": (100, 550),\n",
    "            \"max_depth\": (6,15),\n",
    "            \"gamma\": (0,10),\n",
    "            \"min_child_weight\": (0,10),\n",
    "            \"subsample\": (0.8,1.0)\n",
    "        },\n",
    "        random_state=1234,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=15, init_points=10)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m--- Optimizing XGBoost RandomForest ---\u001b[0m\n",
      "|   iter    |  target   |   gamma   | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-4.201   \u001b[0m | \u001b[0m 1.915   \u001b[0m | \u001b[0m 11.6    \u001b[0m | \u001b[0m 4.377   \u001b[0m | \u001b[0m 453.4   \u001b[0m | \u001b[0m 0.956   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-4.521   \u001b[0m | \u001b[0m 2.726   \u001b[0m | \u001b[0m 8.488   \u001b[0m | \u001b[0m 8.019   \u001b[0m | \u001b[0m 531.2   \u001b[0m | \u001b[0m 0.9752  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-4.269   \u001b[0m | \u001b[0m 3.578   \u001b[0m | \u001b[0m 10.51   \u001b[0m | \u001b[0m 6.835   \u001b[0m | \u001b[0m 420.7   \u001b[0m | \u001b[0m 0.8741  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-4.299   \u001b[0m | \u001b[0m 5.612   \u001b[0m | \u001b[0m 10.53   \u001b[0m | \u001b[0m 0.1377  \u001b[0m | \u001b[0m 447.8   \u001b[0m | \u001b[0m 0.9765  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-4.234   \u001b[0m | \u001b[0m 3.649   \u001b[0m | \u001b[0m 11.54   \u001b[0m | \u001b[0m 0.7538  \u001b[0m | \u001b[0m 266.0   \u001b[0m | \u001b[0m 0.9866  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-4.377   \u001b[0m | \u001b[0m 6.514   \u001b[0m | \u001b[0m 9.575   \u001b[0m | \u001b[0m 7.887   \u001b[0m | \u001b[0m 242.6   \u001b[0m | \u001b[0m 0.9136  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-4.4     \u001b[0m | \u001b[0m 8.691   \u001b[0m | \u001b[0m 9.926   \u001b[0m | \u001b[0m 8.021   \u001b[0m | \u001b[0m 164.7   \u001b[0m | \u001b[0m 0.9409  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-4.665   \u001b[0m | \u001b[0m 7.046   \u001b[0m | \u001b[0m 7.969   \u001b[0m | \u001b[0m 9.249   \u001b[0m | \u001b[0m 299.0   \u001b[0m | \u001b[0m 0.9819  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-4.628   \u001b[0m | \u001b[0m 0.5981  \u001b[0m | \u001b[0m 7.659   \u001b[0m | \u001b[0m 0.4736  \u001b[0m | \u001b[0m 403.7   \u001b[0m | \u001b[0m 0.9189  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-4.79    \u001b[0m | \u001b[0m 5.333   \u001b[0m | \u001b[0m 6.39    \u001b[0m | \u001b[0m 5.614   \u001b[0m | \u001b[0m 248.4   \u001b[0m | \u001b[0m 0.9006  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-4.619   \u001b[0m | \u001b[0m 5.153   \u001b[0m | \u001b[0m 7.633   \u001b[0m | \u001b[0m 3.77    \u001b[0m | \u001b[0m 134.2   \u001b[0m | \u001b[0m 0.8525  \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m-4.116   \u001b[0m | \u001b[95m 3.824   \u001b[0m | \u001b[95m 13.39   \u001b[0m | \u001b[95m 4.05    \u001b[0m | \u001b[95m 436.9   \u001b[0m | \u001b[95m 0.9551  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-4.646   \u001b[0m | \u001b[0m 1.111   \u001b[0m | \u001b[0m 7.967   \u001b[0m | \u001b[0m 6.716   \u001b[0m | \u001b[0m 486.7   \u001b[0m | \u001b[0m 0.9595  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-4.124   \u001b[0m | \u001b[0m 8.317   \u001b[0m | \u001b[0m 13.26   \u001b[0m | \u001b[0m 0.9797  \u001b[0m | \u001b[0m 271.3   \u001b[0m | \u001b[0m 0.9759  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-4.144   \u001b[0m | \u001b[0m 1.406   \u001b[0m | \u001b[0m 13.6    \u001b[0m | \u001b[0m 6.52    \u001b[0m | \u001b[0m 442.9   \u001b[0m | \u001b[0m 0.9402  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-4.381   \u001b[0m | \u001b[0m 0.1524  \u001b[0m | \u001b[0m 9.631   \u001b[0m | \u001b[0m 9.976   \u001b[0m | \u001b[0m 434.7   \u001b[0m | \u001b[0m 0.8515  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-4.179   \u001b[0m | \u001b[0m 8.876   \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 6.989   \u001b[0m | \u001b[0m 440.9   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m-4.02    \u001b[0m | \u001b[95m 1.69    \u001b[0m | \u001b[95m 15.0    \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 275.6   \u001b[0m | \u001b[95m 0.8886  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-4.159   \u001b[0m | \u001b[0m 0.9454  \u001b[0m | \u001b[0m 14.52   \u001b[0m | \u001b[0m 8.439   \u001b[0m | \u001b[0m 274.1   \u001b[0m | \u001b[0m 0.8815  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-4.618   \u001b[0m | \u001b[0m 0.4591  \u001b[0m | \u001b[0m 7.145   \u001b[0m | \u001b[0m 0.2923  \u001b[0m | \u001b[0m 278.5   \u001b[0m | \u001b[0m 0.8879  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-4.069   \u001b[0m | \u001b[0m 1.87    \u001b[0m | \u001b[0m 14.8    \u001b[0m | \u001b[0m 3.142   \u001b[0m | \u001b[0m 272.5   \u001b[0m | \u001b[0m 0.9234  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-4.046   \u001b[0m | \u001b[0m 7.635   \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 3.742   \u001b[0m | \u001b[0m 278.4   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-4.095   \u001b[0m | \u001b[0m 9.052   \u001b[0m | \u001b[0m 13.48   \u001b[0m | \u001b[0m 0.4914  \u001b[0m | \u001b[0m 429.3   \u001b[0m | \u001b[0m 0.9381  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-4.773   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 434.1   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-4.142   \u001b[0m | \u001b[0m 8.855   \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 7.777   \u001b[0m | \u001b[0m 273.5   \u001b[0m | \u001b[0m 0.9191  \u001b[0m |\n",
      "=====================================================================================\n",
      "Final result: {'target': -4.019930759901191, 'params': {'gamma': 1.6904595841784635, 'max_depth': 15.0, 'min_child_weight': 0.0, 'n_estimators': 275.553942931355, 'subsample': 0.8885871371553521}}\n"
     ]
    }
   ],
   "source": [
    "print(Colours.red(\"--- Optimizing XGBoost RandomForest ---\"))\n",
    "optimize_xgb(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbrf = XGBRFRegressor(\n",
    "        n_estimators=int(275.553942931355),\n",
    "        max_depth = int(15.0),\n",
    "        gamma = 1.6904595841784635,\n",
    "        min_child_weight=0.0,\n",
    "        subsample = 0.8885871371553521,\n",
    "        random_state = 42,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking all the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('etc', etc), ('rfc', rfc), ('xgb', xgb), ('lgb', lgb), ('xgbrf', xgbrf)]\n",
    "\n",
    "model = StackingRegressor(estimators=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.58851075, -3.62890407, -3.85200739, -3.79927921, -3.76554997])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model, x_train, y_train, cv = 5, scoring = rmse)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.726850278518188"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the model performance by ploting the Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "x_train = train.values\n",
    "y_train = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "model , x_train, y_train, train_sizes=np.linspace(0.01, 1.0, 5), scoring=rmse, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean training scores\n",
      "\n",
      " 73      3.857711\n",
      "1883    0.910137\n",
      "3694    1.063144\n",
      "5505    1.004915\n",
      "7316    1.012081\n",
      "dtype: float64\n",
      "\n",
      " --------------------\n",
      "\n",
      "Mean valid scores\n",
      "\n",
      " 73      5.881668\n",
      "1883    4.260384\n",
      "3694    3.971791\n",
      "5505    3.832624\n",
      "7316    3.728119\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_scores_mean = -train_scores.mean(axis = 1)\n",
    "valid_scores_mean = -valid_scores.mean(axis = 1)\n",
    "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
    "print('\\n', '-' * 20) # separator\n",
    "print('\\nMean valid scores\\n\\n',pd.Series(valid_scores_mean, index = train_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cd81617a08>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes, valid_scores_mean, label = 'Validation error')\n",
    "plt.ylabel('RMSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model and Checking its Performance on an Unseen Data\n",
    "\n",
    "### Size of the DataSet : 9146\n",
    "### Size of Train DataSet : 7317 (why ? Because Model has least error for this size of dataset)\n",
    "### Size of Test DataSet : 1829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train,target], axis=1)\n",
    "x_train = df.iloc[:7317,:22].values\n",
    "y_train = df.iloc[:7317,-1].values\n",
    "x_test  = df.iloc[7317:,:22].values\n",
    "y_actual= df.iloc[7317:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7498458048813794"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(y_actual,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
