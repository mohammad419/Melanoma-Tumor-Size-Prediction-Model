{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Regression Project: Melanoma Tumor Size Prediction\n",
    "\n",
    "\n",
    "## Loading Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, StackingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.util import Colours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load: Melanoma Tumor Size into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'E:/Data_Sets/Train_15.csv')\n",
    "test  = pd.read_csv(r'E:/Data_Sets/Test_15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass_npea</th>\n",
       "      <th>size_npear</th>\n",
       "      <th>malign_ratio</th>\n",
       "      <th>damage_size</th>\n",
       "      <th>exposed_area</th>\n",
       "      <th>std_dev_malign</th>\n",
       "      <th>err_malign</th>\n",
       "      <th>malign_penalty</th>\n",
       "      <th>damage_ratio</th>\n",
       "      <th>tumor_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6930.90</td>\n",
       "      <td>2919.02</td>\n",
       "      <td>0.42116</td>\n",
       "      <td>51.8298</td>\n",
       "      <td>9.888294e+05</td>\n",
       "      <td>109.487</td>\n",
       "      <td>2758.76</td>\n",
       "      <td>72</td>\n",
       "      <td>39.3620</td>\n",
       "      <td>14.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15635.70</td>\n",
       "      <td>4879.36</td>\n",
       "      <td>0.31206</td>\n",
       "      <td>223.5500</td>\n",
       "      <td>2.058426e+06</td>\n",
       "      <td>248.881</td>\n",
       "      <td>5952.53</td>\n",
       "      <td>240</td>\n",
       "      <td>22.0253</td>\n",
       "      <td>2.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10376.20</td>\n",
       "      <td>2613.88</td>\n",
       "      <td>0.25191</td>\n",
       "      <td>127.3370</td>\n",
       "      <td>1.434676e+06</td>\n",
       "      <td>160.093</td>\n",
       "      <td>4635.26</td>\n",
       "      <td>73</td>\n",
       "      <td>29.9963</td>\n",
       "      <td>1.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13093.80</td>\n",
       "      <td>4510.06</td>\n",
       "      <td>0.34444</td>\n",
       "      <td>155.4400</td>\n",
       "      <td>1.812195e+06</td>\n",
       "      <td>173.015</td>\n",
       "      <td>5273.87</td>\n",
       "      <td>32</td>\n",
       "      <td>28.1354</td>\n",
       "      <td>3.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7545.21</td>\n",
       "      <td>2882.36</td>\n",
       "      <td>0.38201</td>\n",
       "      <td>85.1237</td>\n",
       "      <td>1.043918e+06</td>\n",
       "      <td>124.414</td>\n",
       "      <td>3263.35</td>\n",
       "      <td>57</td>\n",
       "      <td>35.0200</td>\n",
       "      <td>18.023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mass_npea  size_npear  malign_ratio  damage_size  exposed_area  \\\n",
       "0    6930.90     2919.02       0.42116      51.8298  9.888294e+05   \n",
       "1   15635.70     4879.36       0.31206     223.5500  2.058426e+06   \n",
       "2   10376.20     2613.88       0.25191     127.3370  1.434676e+06   \n",
       "3   13093.80     4510.06       0.34444     155.4400  1.812195e+06   \n",
       "4    7545.21     2882.36       0.38201      85.1237  1.043918e+06   \n",
       "\n",
       "   std_dev_malign  err_malign  malign_penalty  damage_ratio  tumor_size  \n",
       "0         109.487     2758.76              72       39.3620      14.103  \n",
       "1         248.881     5952.53             240       22.0253       2.648  \n",
       "2         160.093     4635.26              73       29.9963       1.688  \n",
       "3         173.015     5273.87              32       28.1354       3.796  \n",
       "4         124.414     3263.35              57       35.0200      18.023  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass_npea</th>\n",
       "      <th>size_npear</th>\n",
       "      <th>malign_ratio</th>\n",
       "      <th>damage_size</th>\n",
       "      <th>exposed_area</th>\n",
       "      <th>std_dev_malign</th>\n",
       "      <th>err_malign</th>\n",
       "      <th>malign_penalty</th>\n",
       "      <th>damage_ratio</th>\n",
       "      <th>tumor_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9.146000e+03</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "      <td>9146.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9903.052174</td>\n",
       "      <td>3032.827837</td>\n",
       "      <td>0.303083</td>\n",
       "      <td>103.902118</td>\n",
       "      <td>1.372442e+06</td>\n",
       "      <td>146.304239</td>\n",
       "      <td>3992.936256</td>\n",
       "      <td>69.849661</td>\n",
       "      <td>34.461652</td>\n",
       "      <td>7.723348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4060.577116</td>\n",
       "      <td>1462.334147</td>\n",
       "      <td>0.062533</td>\n",
       "      <td>55.456862</td>\n",
       "      <td>5.646773e+05</td>\n",
       "      <td>70.512177</td>\n",
       "      <td>1780.672859</td>\n",
       "      <td>55.785332</td>\n",
       "      <td>5.972808</td>\n",
       "      <td>6.086852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2864.760000</td>\n",
       "      <td>510.530000</td>\n",
       "      <td>0.114820</td>\n",
       "      <td>10.310100</td>\n",
       "      <td>3.878534e+05</td>\n",
       "      <td>31.970400</td>\n",
       "      <td>1089.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.228000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6988.420000</td>\n",
       "      <td>1983.657500</td>\n",
       "      <td>0.259053</td>\n",
       "      <td>64.012525</td>\n",
       "      <td>9.596873e+05</td>\n",
       "      <td>95.853900</td>\n",
       "      <td>3177.682500</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.290225</td>\n",
       "      <td>2.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8895.965000</td>\n",
       "      <td>2684.330000</td>\n",
       "      <td>0.301055</td>\n",
       "      <td>88.458300</td>\n",
       "      <td>1.237057e+06</td>\n",
       "      <td>126.138500</td>\n",
       "      <td>3846.320000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>35.245750</td>\n",
       "      <td>5.060500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12119.950000</td>\n",
       "      <td>3830.745000</td>\n",
       "      <td>0.343002</td>\n",
       "      <td>134.209000</td>\n",
       "      <td>1.693083e+06</td>\n",
       "      <td>182.251500</td>\n",
       "      <td>4664.577500</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>38.806075</td>\n",
       "      <td>13.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36995.400000</td>\n",
       "      <td>13535.000000</td>\n",
       "      <td>0.525300</td>\n",
       "      <td>346.420000</td>\n",
       "      <td>4.978616e+06</td>\n",
       "      <td>528.890000</td>\n",
       "      <td>91983.700000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>46.546400</td>\n",
       "      <td>20.999000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mass_npea    size_npear  malign_ratio  damage_size  exposed_area  \\\n",
       "count   9146.000000   9146.000000   9146.000000  9146.000000  9.146000e+03   \n",
       "mean    9903.052174   3032.827837      0.303083   103.902118  1.372442e+06   \n",
       "std     4060.577116   1462.334147      0.062533    55.456862  5.646773e+05   \n",
       "min     2864.760000    510.530000      0.114820    10.310100  3.878534e+05   \n",
       "25%     6988.420000   1983.657500      0.259053    64.012525  9.596873e+05   \n",
       "50%     8895.965000   2684.330000      0.301055    88.458300  1.237057e+06   \n",
       "75%    12119.950000   3830.745000      0.343002   134.209000  1.693083e+06   \n",
       "max    36995.400000  13535.000000      0.525300   346.420000  4.978616e+06   \n",
       "\n",
       "       std_dev_malign    err_malign  malign_penalty  damage_ratio   tumor_size  \n",
       "count     9146.000000   9146.000000     9146.000000   9146.000000  9146.000000  \n",
       "mean       146.304239   3992.936256       69.849661     34.461652     7.723348  \n",
       "std         70.512177   1780.672859       55.785332      5.972808     6.086852  \n",
       "min         31.970400   1089.190000        0.000000     15.228000     0.000000  \n",
       "25%         95.853900   3177.682500       31.000000     30.290225     2.320000  \n",
       "50%        126.138500   3846.320000       54.000000     35.245750     5.060500  \n",
       "75%        182.251500   4664.577500       91.000000     38.806075    13.336000  \n",
       "max        528.890000  91983.700000      340.000000     46.546400    20.999000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train.pop('tumor_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['exposed_area'] = np.log1p(train['exposed_area'])\n",
    "\n",
    "test['exposed_area'] = np.log1p(test['exposed_area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "## Deriving new columns from the existing in order to have more information available for the model to learn so that it can perform with better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['penalty-err'] = train['malign_penalty'] - train['err_malign']\n",
    "train['d_size-ratio'] = train['damage_size'] - train['damage_ratio']\n",
    "train['d_ratio-m_ratio'] = train['damage_ratio'] - (train['malign_ratio'])\n",
    "train['penalty/std'] = train['malign_penalty']/train['std_dev_malign']\n",
    "train['mass/area'] = (train['mass_npea'])/(train['exposed_area'])\n",
    "train['area/mass'] = train['exposed_area']/train['mass_npea']\n",
    "train['err/std'] = train['penalty-err']/train['std_dev_malign']\n",
    "train['dsr/ps'] = train['damage_size']/train['penalty-err']\n",
    "train['std/area'] = train['std_dev_malign']/train['exposed_area']\n",
    "train['err/area'] = train['err_malign']/train['exposed_area']\n",
    "train['dr/area'] = (train['damage_ratio']*100)/train['exposed_area']\n",
    "train['std/err'] = (train['std_dev_malign']+1)/(train['err_malign']+1)\n",
    "train['penalty/err'] = (train['malign_penalty']+1)/(train['err_malign']+1)\n",
    "\n",
    "test['penalty-err'] = test['malign_penalty'] - test['err_malign']\n",
    "test['d_size-ratio'] = test['damage_size'] - test['damage_ratio']\n",
    "test['d_ratio-m_ratio'] = test['damage_ratio'] - (test['malign_ratio'])\n",
    "test['penalty/std'] = test['malign_penalty']/test['std_dev_malign']\n",
    "test['mass/area'] = (test['mass_npea'])/(test['exposed_area'])\n",
    "test['area/mass'] = test['exposed_area']/test['mass_npea']\n",
    "test['err/std'] = test['penalty-err']/test['std_dev_malign']\n",
    "test['dsr/ps'] = test['damage_size']/test['penalty-err']\n",
    "test['std/area'] = test['std_dev_malign']/test['exposed_area']\n",
    "test['err/area'] = test['err_malign']/test['exposed_area']\n",
    "test['dr/area'] = (test['damage_ratio']*100)/test['exposed_area']\n",
    "test['std/err'] = (test['std_dev_malign']+1)/(test['err_malign']+1)\n",
    "test['penalty/err'] = (test['malign_penalty']+1)/(test['err_malign']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9146 entries, 0 to 9145\n",
      "Data columns (total 22 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   mass_npea        9146 non-null   float64\n",
      " 1   size_npear       9146 non-null   float64\n",
      " 2   malign_ratio     9146 non-null   float64\n",
      " 3   damage_size      9146 non-null   float64\n",
      " 4   exposed_area     9146 non-null   float64\n",
      " 5   std_dev_malign   9146 non-null   float64\n",
      " 6   err_malign       9146 non-null   float64\n",
      " 7   malign_penalty   9146 non-null   int64  \n",
      " 8   damage_ratio     9146 non-null   float64\n",
      " 9   penalty-err      9146 non-null   float64\n",
      " 10  d_size-ratio     9146 non-null   float64\n",
      " 11  d_ratio-m_ratio  9146 non-null   float64\n",
      " 12  penalty/std      9146 non-null   float64\n",
      " 13  mass/area        9146 non-null   float64\n",
      " 14  area/mass        9146 non-null   float64\n",
      " 15  err/std          9146 non-null   float64\n",
      " 16  dsr/ps           9146 non-null   float64\n",
      " 17  std/area         9146 non-null   float64\n",
      " 18  err/area         9146 non-null   float64\n",
      " 19  dr/area          9146 non-null   float64\n",
      " 20  std/err          9146 non-null   float64\n",
      " 21  penalty/err      9146 non-null   float64\n",
      "dtypes: float64(21), int64(1)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true,y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true,y_pred))\n",
    "rmse = make_scorer(RMSE, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of Extratrees Regressor using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etc_cv(n_estimators, min_samples_split, max_features, data, target):\n",
    "    estimator = ExtraTreesRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            min_samples_split=min_samples_split,\n",
    "            max_features=max_features,\n",
    "            random_state=2,\n",
    "            n_jobs=-1\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, target, scoring=rmse, cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_etc(data, target):\n",
    "    def etc_crossval(n_estimators, min_samples_split, max_features):\n",
    "        return etc_cv(\n",
    "                n_estimators=int(n_estimators),\n",
    "                min_samples_split=int(min_samples_split),\n",
    "                max_features=max(min(max_features, 0.999), 1e-3),\n",
    "                data=data,\n",
    "                target=target,\n",
    "                )\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=etc_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\":(100,400),\n",
    "            \"min_samples_split\":(2,25),\n",
    "            \"max_features\": (0.1,0.9)\n",
    "        },\n",
    "        random_state=42,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=15, init_points=5)\n",
    "    \n",
    "    print(\"Final result:\", optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m--- Optimizing Extra Trees ---\u001b[0m\n",
      "|   iter    |  target   | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-4.092   \u001b[0m | \u001b[0m 0.3996  \u001b[0m | \u001b[0m 23.87   \u001b[0m | \u001b[0m 319.6   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-3.817   \u001b[0m | \u001b[95m 0.5789  \u001b[0m | \u001b[95m 5.588   \u001b[0m | \u001b[95m 146.8   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-4.192   \u001b[0m | \u001b[0m 0.1465  \u001b[0m | \u001b[0m 21.92   \u001b[0m | \u001b[0m 280.3   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-3.779   \u001b[0m | \u001b[95m 0.6665  \u001b[0m | \u001b[95m 2.473   \u001b[0m | \u001b[95m 391.0   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-3.83    \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 6.884   \u001b[0m | \u001b[0m 154.5   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-4.066   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-3.772   \u001b[0m | \u001b[95m 0.3464  \u001b[0m | \u001b[95m 2.026   \u001b[0m | \u001b[95m 392.3   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-4.331   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 400.0   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-4.333   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 145.0   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-3.789   \u001b[0m | \u001b[0m 0.7983  \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 171.4   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-3.787   \u001b[0m | \u001b[0m 0.4474  \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 189.9   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-4.014   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 20.98   \u001b[0m | \u001b[0m 187.0   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-3.863   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 209.9   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-3.857   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 364.5   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-3.792   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 236.5   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-4.191   \u001b[0m | \u001b[0m 0.1731  \u001b[0m | \u001b[0m 21.72   \u001b[0m | \u001b[0m 230.5   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-3.791   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 251.8   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-4.118   \u001b[0m | \u001b[0m 0.3029  \u001b[0m | \u001b[0m 23.89   \u001b[0m | \u001b[0m 357.3   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-3.798   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 126.1   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-3.801   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 108.2   \u001b[0m |\n",
      "=============================================================\n",
      "Final result: {'target': -3.7718781127340093, 'params': {'max_features': 0.34640819636969217, 'min_samples_split': 2.0259434886125725, 'n_estimators': 392.3242333129391}}\n"
     ]
    }
   ],
   "source": [
    "print(Colours.yellow(\"--- Optimizing Extra Trees ---\"))\n",
    "optimize_etc(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = ExtraTreesRegressor(n_estimators=int(392.3242333129391),\n",
    "                         min_samples_split=int(2.0259434886125725),\n",
    "                         max_features=0.34640819636969217,\n",
    "                         n_jobs = -1,\n",
    "                         random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of RandomForest Regressor using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_cv(n_estimators, min_samples_split, max_features, data, target):\n",
    "    estimator = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            min_samples_split=min_samples_split,\n",
    "            max_features=max_features,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, target, scoring=rmse, cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_rfc(data, target):\n",
    "    def rfc_crossval(n_estimators, min_samples_split, max_features):\n",
    "        return rfc_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            max_features=max(min(max_features, 0.9), 1e-3),\n",
    "            data=data,\n",
    "            target=target,\n",
    "            )\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=rfc_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\":(100,500),\n",
    "            \"min_samples_split\":(2,25),\n",
    "            \"max_features\":(0.1,0.9),\n",
    "        },\n",
    "        random_state=1234,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=15, init_points=10)\n",
    "    \n",
    "    print(\"Final result:\", optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m--- Optimizing Random Forest ---\u001b[0m\n",
      "|   iter    |  target   | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-4.044   \u001b[0m | \u001b[0m 0.2532  \u001b[0m | \u001b[0m 16.31   \u001b[0m | \u001b[0m 275.1   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-4.098   \u001b[0m | \u001b[0m 0.7283  \u001b[0m | \u001b[0m 19.94   \u001b[0m | \u001b[0m 209.0   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-4.074   \u001b[0m | \u001b[0m 0.3212  \u001b[0m | \u001b[0m 20.44   \u001b[0m | \u001b[0m 483.3   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-4.022   \u001b[0m | \u001b[95m 0.8007  \u001b[0m | \u001b[95m 10.23   \u001b[0m | \u001b[95m 300.4   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-4.077   \u001b[0m | \u001b[0m 0.6468  \u001b[0m | \u001b[0m 18.39   \u001b[0m | \u001b[0m 248.1   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-4.037   \u001b[0m | \u001b[0m 0.549   \u001b[0m | \u001b[0m 13.57   \u001b[0m | \u001b[0m 105.5   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-4.117   \u001b[0m | \u001b[0m 0.7183  \u001b[0m | \u001b[0m 22.3    \u001b[0m | \u001b[0m 246.0   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-3.947   \u001b[0m | \u001b[95m 0.5923  \u001b[0m | \u001b[95m 3.734   \u001b[0m | \u001b[95m 247.5   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-4.077   \u001b[0m | \u001b[0m 0.8465  \u001b[0m | \u001b[0m 16.98   \u001b[0m | \u001b[0m 258.9   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-4.015   \u001b[0m | \u001b[0m 0.731   \u001b[0m | \u001b[0m 9.287   \u001b[0m | \u001b[0m 327.2   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-3.924   \u001b[0m | \u001b[95m 0.1662  \u001b[0m | \u001b[95m 2.0     \u001b[0m | \u001b[95m 243.5   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-3.977   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 232.8   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-4.193   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 349.8   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-3.976   \u001b[0m | \u001b[0m 0.7313  \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 142.6   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-4.121   \u001b[0m | \u001b[0m 0.7447  \u001b[0m | \u001b[0m 22.43   \u001b[0m | \u001b[0m 145.3   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-3.934   \u001b[0m | \u001b[0m 0.4209  \u001b[0m | \u001b[0m 2.432   \u001b[0m | \u001b[0m 126.2   \u001b[0m |\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m-3.922   \u001b[0m | \u001b[95m 0.4101  \u001b[0m | \u001b[95m 2.489   \u001b[0m | \u001b[95m 421.7   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-4.095   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 18.95   \u001b[0m | \u001b[0m 422.6   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-3.941   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 409.7   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-3.94    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 437.9   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-3.974   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 456.2   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-3.975   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 388.8   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-3.943   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 174.9   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-4.126   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 18.37   \u001b[0m | \u001b[0m 178.3   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-3.944   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 161.9   \u001b[0m |\n",
      "=============================================================\n",
      "Final result: {'target': -3.921953191672343, 'params': {'max_features': 0.41013558840105446, 'min_samples_split': 2.4893231506864923, 'n_estimators': 421.6986461274645}}\n"
     ]
    }
   ],
   "source": [
    "print(Colours.green(\"--- Optimizing Random Forest ---\"))\n",
    "optimize_rfc(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestRegressor(n_estimators = int(421.6986461274645),\n",
    "                           min_samples_split=int(2.4893231506864923),\n",
    "                           max_features = 0.41013558840105446,\n",
    "                           n_jobs = -1, \n",
    "                           random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of LightGradientBoosting Regressor using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_cv(n_estimators, num_leaves, min_child_samples, subsample, data, target):\n",
    "    estimator = LGBMRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        num_leaves=num_leaves,\n",
    "        min_child_samples=min_child_samples,\n",
    "        subsample=subsample,\n",
    "        random_state=2\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, target, scoring=rmse, cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_lgb(data, targets):\n",
    "    def lgb_crossval(n_estimators, num_leaves, min_child_samples, subsample):\n",
    "        return lgb_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "            num_leaves= int(num_leaves),\n",
    "            min_child_samples=int(min_child_samples),\n",
    "            subsample=subsample,\n",
    "            data=data,\n",
    "            target=target,\n",
    "        )\n",
    "    \n",
    "    optimizer = BayesianOptimization(\n",
    "        f=lgb_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\":(100,500),\n",
    "            \"num_leaves\":(30,90),\n",
    "            \"min_child_samples\":(5,30),\n",
    "            \"subsample\":(0.6,1.0)\n",
    "        },\n",
    "        random_state=1234,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=15, init_points=20)\n",
    "    \n",
    "    print(\"Final result:\", optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m--- Optimizing Light GBM ---\u001b[0m\n",
      "|   iter    |  target   | min_ch... | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-3.98    \u001b[0m | \u001b[0m 9.788   \u001b[0m | \u001b[0m 348.8   \u001b[0m | \u001b[0m 56.26   \u001b[0m | \u001b[0m 0.9141  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-4.015   \u001b[0m | \u001b[0m 24.5    \u001b[0m | \u001b[0m 209.0   \u001b[0m | \u001b[0m 46.59   \u001b[0m | \u001b[0m 0.9207  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-3.982   \u001b[0m | \u001b[0m 28.95   \u001b[0m | \u001b[0m 450.4   \u001b[0m | \u001b[0m 51.47   \u001b[0m | \u001b[0m 0.8004  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-3.986   \u001b[0m | \u001b[0m 22.09   \u001b[0m | \u001b[0m 385.1   \u001b[0m | \u001b[0m 52.22   \u001b[0m | \u001b[0m 0.8245  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-4.024   \u001b[0m | \u001b[0m 17.58   \u001b[0m | \u001b[0m 105.5   \u001b[0m | \u001b[0m 76.37   \u001b[0m | \u001b[0m 0.9531  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-4.019   \u001b[0m | \u001b[0m 14.12   \u001b[0m | \u001b[0m 346.2   \u001b[0m | \u001b[0m 34.52   \u001b[0m | \u001b[0m 0.7475  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-3.993   \u001b[0m | \u001b[0m 28.33   \u001b[0m | \u001b[0m 360.6   \u001b[0m | \u001b[0m 53.83   \u001b[0m | \u001b[0m 0.9155  \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-3.972   \u001b[0m | \u001b[95m 12.92   \u001b[0m | \u001b[95m 327.2   \u001b[0m | \u001b[95m 82.15   \u001b[0m | \u001b[95m 0.7745  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-3.995   \u001b[0m | \u001b[0m 25.05   \u001b[0m | \u001b[0m 157.5   \u001b[0m | \u001b[0m 72.26   \u001b[0m | \u001b[0m 0.8818  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-3.972   \u001b[0m | \u001b[0m 10.47   \u001b[0m | \u001b[0m 469.9   \u001b[0m | \u001b[0m 56.53   \u001b[0m | \u001b[0m 0.9637  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-4.078   \u001b[0m | \u001b[0m 6.495   \u001b[0m | \u001b[0m 173.7   \u001b[0m | \u001b[0m 32.84   \u001b[0m | \u001b[0m 0.87    \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-4.003   \u001b[0m | \u001b[0m 19.87   \u001b[0m | \u001b[0m 313.3   \u001b[0m | \u001b[0m 32.6    \u001b[0m | \u001b[0m 0.8246  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-4.0     \u001b[0m | \u001b[0m 13.24   \u001b[0m | \u001b[0m 301.2   \u001b[0m | \u001b[0m 36.71   \u001b[0m | \u001b[0m 0.8429  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-4.028   \u001b[0m | \u001b[0m 19.15   \u001b[0m | \u001b[0m 102.7   \u001b[0m | \u001b[0m 67.05   \u001b[0m | \u001b[0m 0.9648  \u001b[0m |\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m-3.97    \u001b[0m | \u001b[95m 24.76   \u001b[0m | \u001b[95m 496.8   \u001b[0m | \u001b[95m 87.53   \u001b[0m | \u001b[95m 0.9168  \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m-3.959   \u001b[0m | \u001b[95m 12.13   \u001b[0m | \u001b[95m 350.0   \u001b[0m | \u001b[95m 58.69   \u001b[0m | \u001b[95m 0.6783  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-4.02    \u001b[0m | \u001b[0m 14.56   \u001b[0m | \u001b[0m 121.5   \u001b[0m | \u001b[0m 57.1    \u001b[0m | \u001b[0m 0.9928  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-3.988   \u001b[0m | \u001b[0m 8.099   \u001b[0m | \u001b[0m 147.8   \u001b[0m | \u001b[0m 74.31   \u001b[0m | \u001b[0m 0.8349  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-4.053   \u001b[0m | \u001b[0m 16.79   \u001b[0m | \u001b[0m 142.9   \u001b[0m | \u001b[0m 43.75   \u001b[0m | \u001b[0m 0.96    \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-4.021   \u001b[0m | \u001b[0m 15.42   \u001b[0m | \u001b[0m 314.3   \u001b[0m | \u001b[0m 30.37   \u001b[0m | \u001b[0m 0.7203  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-3.976   \u001b[0m | \u001b[0m 16.75   \u001b[0m | \u001b[0m 347.9   \u001b[0m | \u001b[0m 69.91   \u001b[0m | \u001b[0m 0.6     \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-3.967   \u001b[0m | \u001b[0m 12.68   \u001b[0m | \u001b[0m 359.7   \u001b[0m | \u001b[0m 63.34   \u001b[0m | \u001b[0m 0.6     \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-3.972   \u001b[0m | \u001b[0m 19.37   \u001b[0m | \u001b[0m 485.6   \u001b[0m | \u001b[0m 74.92   \u001b[0m | \u001b[0m 0.9266  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-3.992   \u001b[0m | \u001b[0m 25.78   \u001b[0m | \u001b[0m 469.4   \u001b[0m | \u001b[0m 65.43   \u001b[0m | \u001b[0m 0.8567  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-3.965   \u001b[0m | \u001b[0m 8.71    \u001b[0m | \u001b[0m 493.7   \u001b[0m | \u001b[0m 85.32   \u001b[0m | \u001b[0m 0.7397  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-3.978   \u001b[0m | \u001b[0m 15.66   \u001b[0m | \u001b[0m 480.6   \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.6     \u001b[0m |\n",
      "| \u001b[95m 27      \u001b[0m | \u001b[95m-3.955   \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 490.2   \u001b[0m | \u001b[95m 65.78   \u001b[0m | \u001b[95m 0.6     \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-3.975   \u001b[0m | \u001b[0m 13.63   \u001b[0m | \u001b[0m 499.4   \u001b[0m | \u001b[0m 65.46   \u001b[0m | \u001b[0m 0.8446  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-3.982   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 487.5   \u001b[0m | \u001b[0m 49.66   \u001b[0m | \u001b[0m 0.6     \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-3.971   \u001b[0m | \u001b[0m 6.357   \u001b[0m | \u001b[0m 479.8   \u001b[0m | \u001b[0m 74.67   \u001b[0m | \u001b[0m 0.8672  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-3.984   \u001b[0m | \u001b[0m 26.4    \u001b[0m | \u001b[0m 315.7   \u001b[0m | \u001b[0m 69.63   \u001b[0m | \u001b[0m 0.6     \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-3.983   \u001b[0m | \u001b[0m 8.712   \u001b[0m | \u001b[0m 309.8   \u001b[0m | \u001b[0m 88.43   \u001b[0m | \u001b[0m 0.8107  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-3.992   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 453.3   \u001b[0m | \u001b[0m 41.82   \u001b[0m | \u001b[0m 0.6     \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-3.961   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 75.02   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-3.97    \u001b[0m | \u001b[0m 29.83   \u001b[0m | \u001b[0m 326.4   \u001b[0m | \u001b[0m 89.98   \u001b[0m | \u001b[0m 0.6753  \u001b[0m |\n",
      "=========================================================================\n",
      "Final result: {'target': -3.955030698426286, 'params': {'min_child_samples': 5.0, 'n_estimators': 490.23543329860655, 'num_leaves': 65.78052355195761, 'subsample': 0.6}}\n"
     ]
    }
   ],
   "source": [
    "print(Colours.blue(\"--- Optimizing Light GBM ---\"))\n",
    "optimize_lgb(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMRegressor(\n",
    "        n_estimators=int(490.23543329860655),\n",
    "        num_leaves = int(65.78052355195761),\n",
    "        min_child_samples=int(5.0),\n",
    "        subsample = 0.6,\n",
    "        random_state = 42\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of ExtremeGradientBoosting Regressor using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv(n_estimators, max_depth, gamma, min_child_weight, subsample, data, target):\n",
    "    estimator = XGBRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            gamma=gamma,\n",
    "            min_child_weight=min_child_weight,\n",
    "            subsample=subsample,\n",
    "            random_state=2\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, target, scoring=rmse, cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_xgb(data, target):\n",
    "    def xgb_crossval(n_estimators, max_depth, gamma, min_child_weight, subsample):\n",
    "        return xgb_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "            max_depth=int(max_depth),\n",
    "            gamma=gamma,\n",
    "            min_child_weight=min_child_weight,\n",
    "            subsample=subsample,\n",
    "            data=data,\n",
    "            target=target,\n",
    "        )\n",
    "    optimizer = BayesianOptimization(\n",
    "            f=xgb_crossval,\n",
    "            pbounds={\n",
    "                \"n_estimators\":(150,500),\n",
    "                \"max_depth\": (1,20),\n",
    "                \"gamma\":(0,10),\n",
    "                \"min_child_weight\":(0,10),\n",
    "                \"subsample\":(0.8,1.0)\n",
    "                },\n",
    "            random_state=1234,\n",
    "            verbose=2\n",
    "      )\n",
    "    optimizer.maximize(n_iter=15 , init_points=10)\n",
    "    \n",
    "    \n",
    "    print('Final Result:', optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m--- Optimizing XGBoost ---\u001b[0m\n",
      "|   iter    |  target   |   gamma   | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-4.244   \u001b[0m | \u001b[0m 1.915   \u001b[0m | \u001b[0m 12.82   \u001b[0m | \u001b[0m 4.377   \u001b[0m | \u001b[0m 424.9   \u001b[0m | \u001b[0m 0.956   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-4.252   \u001b[0m | \u001b[0m 2.726   \u001b[0m | \u001b[0m 6.253   \u001b[0m | \u001b[0m 8.019   \u001b[0m | \u001b[0m 485.3   \u001b[0m | \u001b[0m 0.9752  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-4.3     \u001b[0m | \u001b[0m 3.578   \u001b[0m | \u001b[0m 10.52   \u001b[0m | \u001b[0m 6.835   \u001b[0m | \u001b[0m 399.4   \u001b[0m | \u001b[0m 0.8741  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-4.245   \u001b[0m | \u001b[0m 5.612   \u001b[0m | \u001b[0m 10.56   \u001b[0m | \u001b[0m 0.1377  \u001b[0m | \u001b[0m 420.5   \u001b[0m | \u001b[0m 0.9765  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-4.226   \u001b[0m | \u001b[95m 3.649   \u001b[0m | \u001b[95m 12.69   \u001b[0m | \u001b[95m 0.7538  \u001b[0m | \u001b[95m 279.1   \u001b[0m | \u001b[95m 0.9866  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-4.233   \u001b[0m | \u001b[0m 6.514   \u001b[0m | \u001b[0m 8.547   \u001b[0m | \u001b[0m 7.887   \u001b[0m | \u001b[0m 260.9   \u001b[0m | \u001b[0m 0.9136  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-4.186   \u001b[0m | \u001b[95m 8.691   \u001b[0m | \u001b[95m 9.287   \u001b[0m | \u001b[95m 8.021   \u001b[0m | \u001b[95m 200.3   \u001b[0m | \u001b[95m 0.9409  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-4.203   \u001b[0m | \u001b[0m 7.046   \u001b[0m | \u001b[0m 5.157   \u001b[0m | \u001b[0m 9.249   \u001b[0m | \u001b[0m 304.7   \u001b[0m | \u001b[0m 0.9819  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-4.241   \u001b[0m | \u001b[0m 0.5981  \u001b[0m | \u001b[0m 4.501   \u001b[0m | \u001b[0m 0.4736  \u001b[0m | \u001b[0m 386.2   \u001b[0m | \u001b[0m 0.9189  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-4.219   \u001b[0m | \u001b[0m 5.333   \u001b[0m | \u001b[0m 1.823   \u001b[0m | \u001b[0m 5.614   \u001b[0m | \u001b[0m 265.4   \u001b[0m | \u001b[0m 0.9006  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-4.224   \u001b[0m | \u001b[0m 8.174   \u001b[0m | \u001b[0m 8.578   \u001b[0m | \u001b[0m 7.399   \u001b[0m | \u001b[0m 187.0   \u001b[0m | \u001b[0m 0.9264  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-4.241   \u001b[0m | \u001b[0m 7.969   \u001b[0m | \u001b[0m 9.918   \u001b[0m | \u001b[0m 9.285   \u001b[0m | \u001b[0m 200.3   \u001b[0m | \u001b[0m 0.8726  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-4.223   \u001b[0m | \u001b[0m 1.111   \u001b[0m | \u001b[0m 5.153   \u001b[0m | \u001b[0m 6.716   \u001b[0m | \u001b[0m 450.8   \u001b[0m | \u001b[0m 0.9595  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-4.211   \u001b[0m | \u001b[0m 8.317   \u001b[0m | \u001b[0m 16.32   \u001b[0m | \u001b[0m 0.9797  \u001b[0m | \u001b[0m 283.3   \u001b[0m | \u001b[0m 0.9759  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-4.257   \u001b[0m | \u001b[0m 8.472   \u001b[0m | \u001b[0m 6.517   \u001b[0m | \u001b[0m 6.877   \u001b[0m | \u001b[0m 167.2   \u001b[0m | \u001b[0m 0.8415  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-4.236   \u001b[0m | \u001b[0m 8.48    \u001b[0m | \u001b[0m 1.792   \u001b[0m | \u001b[0m 0.8149  \u001b[0m | \u001b[0m 326.1   \u001b[0m | \u001b[0m 0.9536  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-4.242   \u001b[0m | \u001b[0m 5.608   \u001b[0m | \u001b[0m 7.428   \u001b[0m | \u001b[0m 5.166   \u001b[0m | \u001b[0m 478.4   \u001b[0m | \u001b[0m 0.8213  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-4.256   \u001b[0m | \u001b[0m 3.653   \u001b[0m | \u001b[0m 13.11   \u001b[0m | \u001b[0m 5.402   \u001b[0m | \u001b[0m 499.0   \u001b[0m | \u001b[0m 0.8603  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-4.247   \u001b[0m | \u001b[0m 7.564   \u001b[0m | \u001b[0m 15.97   \u001b[0m | \u001b[0m 3.059   \u001b[0m | \u001b[0m 250.8   \u001b[0m | \u001b[0m 0.9221  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-4.249   \u001b[0m | \u001b[0m 6.385   \u001b[0m | \u001b[0m 15.03   \u001b[0m | \u001b[0m 4.344   \u001b[0m | \u001b[0m 192.8   \u001b[0m | \u001b[0m 0.8045  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-4.214   \u001b[0m | \u001b[0m 4.361   \u001b[0m | \u001b[0m 17.83   \u001b[0m | \u001b[0m 6.2     \u001b[0m | \u001b[0m 416.7   \u001b[0m | \u001b[0m 0.9801  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-4.254   \u001b[0m | \u001b[0m 8.041   \u001b[0m | \u001b[0m 7.955   \u001b[0m | \u001b[0m 6.426   \u001b[0m | \u001b[0m 306.8   \u001b[0m | \u001b[0m 0.8517  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-4.239   \u001b[0m | \u001b[0m 8.742   \u001b[0m | \u001b[0m 17.87   \u001b[0m | \u001b[0m 6.815   \u001b[0m | \u001b[0m 334.3   \u001b[0m | \u001b[0m 0.886   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-4.216   \u001b[0m | \u001b[0m 8.451   \u001b[0m | \u001b[0m 19.22   \u001b[0m | \u001b[0m 3.176   \u001b[0m | \u001b[0m 151.6   \u001b[0m | \u001b[0m 0.9945  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-4.242   \u001b[0m | \u001b[0m 4.261   \u001b[0m | \u001b[0m 5.69    \u001b[0m | \u001b[0m 8.07    \u001b[0m | \u001b[0m 303.4   \u001b[0m | \u001b[0m 0.9463  \u001b[0m |\n",
      "=====================================================================================\n",
      "Final Result: {'target': -4.185521147138113, 'params': {'gamma': 8.691273895612259, 'max_depth': 9.287295054017909, 'min_child_weight': 8.02147642080159, 'n_estimators': 200.3183885800976, 'subsample': 0.9408521942236671}}\n"
     ]
    }
   ],
   "source": [
    "print(Colours.red(\"--- Optimizing XGBoost ---\"))\n",
    "optimize_xgb(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(\n",
    "        n_estimators=int(200.3183885800976),\n",
    "        max_depth = int(9.287295054017909),\n",
    "        gamma = 8.691273895612259,\n",
    "        min_child_weight = 8.02147642080159,\n",
    "        subsample = 0.9408521942236671,\n",
    "        random_state = 42,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of ExtremeGradientBoosting and RandomForest Regressor using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv(n_estimators, max_depth, gamma, min_child_weight, subsample, data, targets):\n",
    "    estimator = XGBRFRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth = max_depth,\n",
    "        gamma = gamma,\n",
    "        min_child_weight=min_child_weight,\n",
    "        subsample = subsample,\n",
    "        random_state = 2,\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, targets,\n",
    "                           scoring=rmse, cv=5)\n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_xgb(data, targets):\n",
    "    def xgb_crossval(n_estimators, max_depth, gamma, min_child_weight, subsample):\n",
    "        return xgb_cv(\n",
    "            n_estimators=int(n_estimators),\n",
    "            max_depth = int(max_depth),\n",
    "            gamma = gamma,\n",
    "            min_child_weight=min_child_weight,\n",
    "            subsample=subsample,\n",
    "            data=data,\n",
    "            targets=targets,\n",
    "        )\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=xgb_crossval,\n",
    "        pbounds={\n",
    "            \"n_estimators\": (200, 500),\n",
    "            \"max_depth\": (6,15),\n",
    "            \"gamma\": (0,10),\n",
    "            \"min_child_weight\": (0,10),\n",
    "            \"subsample\": (0.8,1.0)\n",
    "        },\n",
    "        random_state=1234,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=15, init_points=10)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m--- Optimizing XGBoost RandomForest ---\u001b[0m\n",
      "|   iter    |  target   |   gamma   | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-4.197   \u001b[0m | \u001b[0m 1.915   \u001b[0m | \u001b[0m 11.6    \u001b[0m | \u001b[0m 4.377   \u001b[0m | \u001b[0m 435.6   \u001b[0m | \u001b[0m 0.956   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-4.504   \u001b[0m | \u001b[0m 2.726   \u001b[0m | \u001b[0m 8.488   \u001b[0m | \u001b[0m 8.019   \u001b[0m | \u001b[0m 487.4   \u001b[0m | \u001b[0m 0.9752  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-4.265   \u001b[0m | \u001b[0m 3.578   \u001b[0m | \u001b[0m 10.51   \u001b[0m | \u001b[0m 6.835   \u001b[0m | \u001b[0m 413.8   \u001b[0m | \u001b[0m 0.8741  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-4.287   \u001b[0m | \u001b[0m 5.612   \u001b[0m | \u001b[0m 10.53   \u001b[0m | \u001b[0m 0.1377  \u001b[0m | \u001b[0m 431.8   \u001b[0m | \u001b[0m 0.9765  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-4.228   \u001b[0m | \u001b[0m 3.649   \u001b[0m | \u001b[0m 11.54   \u001b[0m | \u001b[0m 0.7538  \u001b[0m | \u001b[0m 310.6   \u001b[0m | \u001b[0m 0.9866  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-4.364   \u001b[0m | \u001b[0m 6.514   \u001b[0m | \u001b[0m 9.575   \u001b[0m | \u001b[0m 7.887   \u001b[0m | \u001b[0m 295.1   \u001b[0m | \u001b[0m 0.9136  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-4.381   \u001b[0m | \u001b[0m 8.691   \u001b[0m | \u001b[0m 9.926   \u001b[0m | \u001b[0m 8.021   \u001b[0m | \u001b[0m 243.1   \u001b[0m | \u001b[0m 0.9409  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-4.643   \u001b[0m | \u001b[0m 7.046   \u001b[0m | \u001b[0m 7.969   \u001b[0m | \u001b[0m 9.249   \u001b[0m | \u001b[0m 332.6   \u001b[0m | \u001b[0m 0.9819  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-4.605   \u001b[0m | \u001b[0m 0.5981  \u001b[0m | \u001b[0m 7.659   \u001b[0m | \u001b[0m 0.4736  \u001b[0m | \u001b[0m 402.5   \u001b[0m | \u001b[0m 0.9189  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-4.754   \u001b[0m | \u001b[0m 5.333   \u001b[0m | \u001b[0m 6.39    \u001b[0m | \u001b[0m 5.614   \u001b[0m | \u001b[0m 298.9   \u001b[0m | \u001b[0m 0.9006  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-4.585   \u001b[0m | \u001b[0m 5.153   \u001b[0m | \u001b[0m 7.633   \u001b[0m | \u001b[0m 3.77    \u001b[0m | \u001b[0m 222.8   \u001b[0m | \u001b[0m 0.8525  \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m-4.113   \u001b[0m | \u001b[95m 3.824   \u001b[0m | \u001b[95m 13.39   \u001b[0m | \u001b[95m 4.05    \u001b[0m | \u001b[95m 424.6   \u001b[0m | \u001b[95m 0.9551  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-4.62    \u001b[0m | \u001b[0m 1.111   \u001b[0m | \u001b[0m 7.967   \u001b[0m | \u001b[0m 6.716   \u001b[0m | \u001b[0m 457.8   \u001b[0m | \u001b[0m 0.9595  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-4.124   \u001b[0m | \u001b[0m 8.317   \u001b[0m | \u001b[0m 13.26   \u001b[0m | \u001b[0m 0.9797  \u001b[0m | \u001b[0m 314.2   \u001b[0m | \u001b[0m 0.9759  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-4.164   \u001b[0m | \u001b[0m 1.646   \u001b[0m | \u001b[0m 12.86   \u001b[0m | \u001b[0m 6.113   \u001b[0m | \u001b[0m 429.1   \u001b[0m | \u001b[0m 0.9364  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-4.467   \u001b[0m | \u001b[0m 4.029   \u001b[0m | \u001b[0m 8.161   \u001b[0m | \u001b[0m 7.494   \u001b[0m | \u001b[0m 423.5   \u001b[0m | \u001b[0m 0.8717  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-4.141   \u001b[0m | \u001b[0m 6.085   \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 4.219   \u001b[0m | \u001b[0m 428.5   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m-4.059   \u001b[0m | \u001b[95m 0.3548  \u001b[0m | \u001b[95m 14.98   \u001b[0m | \u001b[95m 0.4963  \u001b[0m | \u001b[95m 425.6   \u001b[0m | \u001b[95m 0.937   \u001b[0m |\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m-4.031   \u001b[0m | \u001b[95m 0.1277  \u001b[0m | \u001b[95m 14.89   \u001b[0m | \u001b[95m 0.2884  \u001b[0m | \u001b[95m 417.7   \u001b[0m | \u001b[95m 0.851   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-4.033   \u001b[0m | \u001b[0m 6.697   \u001b[0m | \u001b[0m 14.25   \u001b[0m | \u001b[0m 1.288   \u001b[0m | \u001b[0m 418.0   \u001b[0m | \u001b[0m 0.8513  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-4.167   \u001b[0m | \u001b[0m 9.74    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 285.4   \u001b[0m | \u001b[0m 0.9515  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-4.236   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 11.3    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 280.4   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-4.044   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 277.6   \u001b[0m | \u001b[0m 0.9272  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-4.807   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 6.637   \u001b[0m | \u001b[0m 1.99    \u001b[0m | \u001b[0m 273.5   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[95m 25      \u001b[0m | \u001b[95m-4.006   \u001b[0m | \u001b[95m 8.17    \u001b[0m | \u001b[95m 15.0    \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 284.7   \u001b[0m | \u001b[95m 0.8     \u001b[0m |\n",
      "=====================================================================================\n",
      "Final result: {'target': -4.006087036989607, 'params': {'gamma': 8.16966206019828, 'max_depth': 15.0, 'min_child_weight': 0.0, 'n_estimators': 284.6733469057235, 'subsample': 0.8}}\n"
     ]
    }
   ],
   "source": [
    "print(Colours.red(\"--- Optimizing XGBoost RandomForest ---\"))\n",
    "optimize_xgb(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbrf = XGBRFRegressor(\n",
    "        n_estimators=int(284.6733469057235),\n",
    "        max_depth = int(15.0),\n",
    "        gamma = 8.16966206019828,\n",
    "        min_child_weight=0.0,\n",
    "        subsample = 0.8,\n",
    "        random_state = 42,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking all the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('etc', etc), ('rfc', rfc), ('xgb', xgb), ('lgb', lgb), ('xgbrf', xgbrf)]\n",
    "\n",
    "model = StackingRegressor(estimators=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.57868487, -3.62815384, -3.8190788 , -3.77845183, -3.72005502])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model, train, target, cv = 5, scoring = rmse)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.704884871290338"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the model performance by ploting the Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "x_train = train.values\n",
    "y_train = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "model , x_train, y_train, train_sizes=np.linspace(0.01, 1.0, 6), scoring='neg_root_mean_squared_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean training scores\n",
      "\n",
      " 73      3.336721\n",
      "1521    1.389713\n",
      "2970    1.520303\n",
      "4418    1.429074\n",
      "5867    1.369761\n",
      "7316    1.303635\n",
      "dtype: float64\n",
      "\n",
      " --------------------\n",
      "\n",
      "Mean valid scores\n",
      "\n",
      " 73      5.669373\n",
      "1521    4.242629\n",
      "2970    3.990072\n",
      "4418    3.900751\n",
      "5867    3.784567\n",
      "7316    3.703136\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_scores_mean = -train_scores.mean(axis = 1)\n",
    "valid_scores_mean = -valid_scores.mean(axis = 1)\n",
    "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
    "print('\\n', '-' * 20) # separator\n",
    "print('\\nMean valid scores\\n\\n',pd.Series(valid_scores_mean, index = train_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12fc0536808>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes, valid_scores_mean, label = 'Validation error')\n",
    "plt.ylabel('RMSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model Accuracy(RMSE) is 3.704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
